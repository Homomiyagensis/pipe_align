#!/usr/bin/env bash
set -ex
################################################################################
                              #pipe_align
          #Pipeline for Transcriptome assembly and Expression Analysis
                    #based on illumina RNA-seq reads
################################################################################

#setting commas as decimals while the shell script is running
export LC_ALL="en_US.UTF-8"
#number of threads set by default when program argument is able
#the number of threads is set to number of threads avialable minus 2
t=$(lscpu|awk 'NR==4{print $2-2}')

################################################################################
#Function usage
################################################################################
function usage {
    echo -e "pipe_align 0.1"
    echo -e "\nusage:\tpipe_align [args] skip [values]"
    echo -e "\nwhere arguments -args- can be:"
    echo -e "\n\t-t\tPass the input table to pipe_align.\n\t\tWhere the first column must have the sra RUN code.\n\t\t\
The second column must have the library layout,and\n\t\tthe third column the read size. It must be provided."
    echo -e "\t-w\tFull path to an existing working directory.\n\t\tThe directory must be already created with mkdir."
    echo -e "\t-p\tProject name. It must be provided."
    echo -e "\t-a\tAdapter sequence that will be used in the trimming process"
    echo -e "\t-P\tNumber of [sra|fastq] files that will be downloaded in parallel"
    echo -e "\t-G\tFull path to fasta file of genome to be used at the read aligning step.\
\n\t\tIt must be provided."
    echo -e "\t-g\tFull path to gtf file with genomic coordinate information of\
\n\t\tgenomic features. The gtf  file must be compatible with the provided\
 genome (same chromosome names). It must be provided."
    echo -e "\t-b\tFull path to bed file with genomic coordinate information of\
\n\t\tgenomic features. The bed file must be compatible with the provided\
\n\t\tgenome (same Chromosome names). It must be provided."
    echo -e "\t-i\tFull path to star index directory, that must be builded using\n\t\t\
the provided genome. If star index directory is provided, the star index build step will be skipped."
    echo -e "\t-I\tFull path to kallisto index file from a curated source is provided"
    echo -e "\t-s\tFull path to directory of sra files, where sra will be read from\n\t\t\
or download to. If it is not provided a directory will be create in the working directory."
    echo -e "\t-f\tFull path to directory of fastq files;where fastq files will be read out\n\t\t\
or download to. If it is not provided a directory will be created in the working directory."
    echo -e "\t-m\tFull path to directory of trimmed_files, where trimmed files will be read from\n\t\t\
or download to. If it is not provided a directory will be created in the workinng directory"
    echo -e "\t-F\tFull path to gtf file, from which attributes will be extracted and added to gtf used for star index genome building.\n\t\t\
It must have the same transcript_id and gene_id attributes as the gtf file provided for star index building."
    echo -e "\t-T\tNumber of threads used for running programs,when is possible.\n\t\t\
By default is set to (( (# of threads in the working cpu) -2 ))".
    echo -e "\t-c\t[human|mouse|zebrafish]one species name for running CPAT with taco_refcompare."
    echo -e "\t-v\tFull path to directory for html web visualization."
    echo -e "\n"
    echo -e "\tskip\tPass values for skipping pipe_align steps:\n\t\tsra\tDownload of sra files will be skipped.\
\n\t\t\tIf skipped a directory for sra files must be provided with -s.\n\t\tdump\tFastq-dump step will be skipped.\
\n\t\t\tIf skipped a directory for fastq files must be provided with -f.\n\t\ttrim\tTrimming step,FASTQC for trimmed files\
\n\t\t\tand reads alignmet by star of trimmed files will be skipped.\n\t\t\tIf trim is provided,then star alignment of\
 untrimmed files will be run.\n\t\tfqc\tFASTQC running will be skipped in all steps.\n\t\t\
fastp\tfastp will be skipped and all downstream steps will run with untrimmed raw fastq files.\n\t\tqc_trim\t\
FASTQC run for trimmed fastq files will be skipped.\n\t\tqc_bam\tFASTQC run for bam files will be skipped.\
\n\t\tbw\tBigWig files generation from star bam files will be skipped.\
\n\t\tsqc\tQuality control of bam files for splicing analysis will be skipped.\
\n\t\tcov\tCoverage analysis of all samples will be skipped."
    echo -e "\n"
    echo -e "\t-h\tdisplay help"
    echo -e "\n"
}
################################################################################
#setting the global variables
################################################################################
#First assigning variables to passed parameters
echo -e "\n" #it will add an empty before running the script
while getopts ":ht:w:p:a:G:P:g:b:i:s:f:F:T:c:v:m:I:V" opts;do
    case "$opts" in
        t)  tb_prim="$OPTARG"
            tb="$tb_prim"
            ;; #input table full path
        w)  wd="$OPTARG";; #working directory full path
        p)  project="$OPTARG";; #project name
        P)  par2="$OPTARG";; #number of files [sra or fastq ] that will be donwloaded in parallel
        a)  adapt="$OPTARG";; #adpater sequence to use in fastp 
        G)  genome="$OPTARG";; #full path to species genome fasta fiel
        g)  gtf_prim="$OPTARG" #full path to gtf primitive file, from a curated source 
            gtf="$gtf_prim" #assigning the the gtf working variable to primitive gtf 
            ;; 
        b)  bed_pri="$OPTARG" #full path to bed primitve file, from a curate database source
            bed="$bed_pri" #assign the bed primitive value to working varaible bed 
            ;;
        i)  staridx="$OPTARG";; #full path to star genome index
        I)  idx_gb="$OPTARG";; #full path to kallisto index for transcriptome testing
        s)  sra="$OPTARG";; #full path to directory of sra files
        f)  pwd1="$OPTARG";; #directory of fastq files
        m)  pwd4="$OPTARG"
            if [ ! -d "$pwd4" ];then
                echo "please provide a full path to a directory as argument for the parameter m" >&2
                exit 1
            fi
            ;; #directory of trimmed_files
        F)  gtf2="$OPTARG";; #full path to gtf file to upgrade
        T)  t="$OPTARG";; #number of threads set when is available in the runnning program
        v)  vd="$OPTARG";; #directory for genomic view track
        c)  species="$OPTARG";; #species name for running taco_compare [human|mouse|zebrafish]
        V)  echo "pipe_align version 0.1"
            exit 0
            ;; #display pipe_align version
        h)
            usage
            exit 0
            ;;
        \?)
            echo -e "\tArgument -$OPTARG is invalid\nprovide a valid argument" >&2
            usage
            exit 1
            ;;
        :)
            echo -e "\tParameter for -$OPTARG is missing" >&2
            usage
            exit 1
            ;;
        *)
            usage
            exit 1
            ;;
    esac
done
shift $(( OPTIND -1 )) #removing already passed parameters

#passing skip positional parameters
subcommand=$1 #assigning the first parameter after getopts parametes
shift #remove pipe_align from argument list
case "$subcommand" in
  skip)
        skipv=("$@") #passing all possitional parameters after skip to skipv
        shift;; #remove skip from argument list
esac

#Mannaging passed arguments
###########################
#exiting the whole script if any mandatory argument has no parameter
if [ -z "$tb" -o ! -f "$tb" ];then
    echo "input table file does not exist" >&2
    exit 1
fi
if [ -z "$genome" -o ! -f "$genome" ];then
    echo "a full path for a genome fasta file does not exist" >&2
    exit 1
fi
if [ -z "$gtf" -o ! -f "$gtf" ];then
    echo "a full path for a gtf does not exist" >&2
    exit 1
fi
if [ -z "$bed" -o ! -f "$bed" ];then
    echo "a full path for a bed file does not exist" >&2
    exit 1
fi

#passed skips and printing them
val=$(for i in "${skipv[@]}";do if [ "$i" == "dump" ];then echo "$i";fi;done)
if [ -n "$val" ];then echo "skipping: fastq-dump step";fi
val1=$(for i in "${skipv[@]}";do if [ "$i" == "sra" ];then echo "$i";fi;done)
if [ -n "$val1" ];then echo "skipping: sra donwload step from the NCBI";fi
val2=$(for i in "${skipv[@]}";do if [ "$i" == "fastp" ];then echo "$i";fi;done)
if [ -n "$val2" ];then echo "skipping: fastp";fi
val3=$(for i in "${skipv[@]}";do if [ "$i" == "fqc" ];then echo "$i";fi;done)
if [ -n "$val3" ];then
    val5="qc_trim"
    val6="qc_bam"
    echo "skipping: fastqc steps from the pipeline"
fi
#val4=$(for i in "${skipv[@]}";do if [ "$i" == "trim" ];then echo "$i";fi;done)
#if [ -n "$val4" ];then echo -e "skipping: trimming step,and all following depending steps\
#\n\t Star will run for untrimmed files.";fi
val5=$(for i in "${skipv[@]}";do if [ "$i" == "qc_trim" ];then echo "$i";fi;done)
if [ -n "$val5" ];then echo "skipping: fastqc step for trimmed fastq files";fi
val6=$(for i in "${skipv[@]}";do if [ "$i" == "qc_bam" ];then echo "$i";fi;done)
if [ -n "$val6" ];then echo "skipping: fastqc step of bam files";fi
val7=$(for i in "${skipv[@]}";do if [ "$i" == "align" ];then echo "$i";fi;done)
if [ -n "$val7" ];then echo "skipping: all alignment steps by star";fi
val8=$(for i in "${skipv[@]}";do if [ "$i" == "bw" ];then echo "$i";fi;done)
if [ -n "$val8" ];then echo "skipping: bigwig generation steps";fi
val9=$(for i in "${skipv[@]}";do if [ "$i" == "sqc" ];then echo "$i";fi;done)
if [ -n "$val9" ];then echo "skipping: splicing quality control steps";fi
val10=$(for i in "${skipv[@]}";do if [ "$i" == "cov" ];then echo "$i";fi;done)
if [ -n "$val10" ];then echo "skipping: coverage analysis step";fi
sleep 2

#exiting the script if sra download is skipped but not sra file directory is provided
if [ "$val1" == "sra" -a ! -d "$sra" ];then
  #and fastq-dump was not skipped
    if [ "$val" != "dump" ];then
      echo "if sra download step is skipped, a full path to an existing \
directory of sra files must be provided.\
\nFull path to sra file directory is missing" >&2
  exit 1
    fi
fi

#exiting the script if fastq dump is skipped but not fastq file directory is provided
if [ "$val" == "dump" -a ! -d "$pwd1" ];then
    echo "if fastq-dump step is skipped, a full path to an existing directory of fastq files must be provided.\
    \nFull path to fastq file directory is missing" >&2
    exit 1
fi

#verifying and creating the working directory -where most of the oupts will be
#written-
#if the working directory was provided then it will be assinged to a varaible
if [ -n "$wd" -a -d "$wd" ]; then
    echo "working directory: $wd"
    #if the provided wd does not exist, the whole script will exit
elif [ -n "$wd" -a ! -d "$wd" ]; then
    echo -e "provided directory does not exist\nplease provide a valid full path to an existing directory" >&2
    exit 1
    #if a working directory is not provided
    #a directory with the project name will be created and set it as wd
elif [ -z "$wd" ];then
    if [ ! -d "$(pwd)/${project}" ];then 
        mkdir "$(pwd)/${project}"
    fi
    wd="$(pwd)/${project}"
    echo "working directory: $wd"
fi

#verifying the provided full path to sra files directory
if [ "$val" != "dump" -a "$val1" != "sra" ];then
    if [ -d "$sra" ];then
        echo "directory of sra files: $sra" #if existing it will be printed
        #or the script will be skipped if the sra directory does not exist
    elif [ -n "$sra" -a ! -d "$sra" ]; then
        echo -e "provided sra directory does not exist\nplease provide a valid path to an existing directory" >&2
        exit 1
        #or created if sra directory was not provided
    elif [ -z "$sra" ];then
        if [ ! -d "$wd/sra" ];then 
            mkdir "$wd/sra"
        fi
        sra="$wd/sra"
        echo "sra dir was created in the working directory"
    fi
fi

#checking and assigning a varaible to passed directory of fastq files
if [ -n "$pwd1" -a -d "$pwd1" ];then
    echo "fastq files directory for raw untrimmed files: $pwd1"
elif [ -n "$pwd1" -a ! -d "$pwd1" ];then
    echo -e "provided directory of fastq files does not \
    exist\nplease provide a valid path to an existing directory" >&2
    exit 1
elif [ -z "$pwd1" ];then
    if [ ! -d "$wd/raw" ];then 
        mkdir "$wd/raw"
    fi
    pwd1="$wd/raw"
    echo "directory for fastq files storage was created at working directory"
fi

#making a genome visualizaton directory for the project
#where files that can be uploaded to genomeBrowser or IGV will be stored
if [ -n "$vd" -a -d "$vd" ]; then
    #creating a dir for the project at the visualization directory
    if [ ! -d "${vd}/${project}" ];then 
        mkdir "${vd}/${project}"
    fi
    #asssigning the variable pwdp to the project directory
    pwdp="${vd}/${project}"
    #if VD directory was provided but does not exist, the whole script will exit
elif [ -n "$vd" ! -a -d "$vd" ];then
    echo -e "the provided $vd does not exist" >&2
    exit 1
    #if not GV directory is provided then a GV directory will be created in
    #the working directory
elif [ -z "$vd" ];then
    if [ ! -d "$wd/genome_view_${project}" ];then
      mkdir "$wd/genome_view_${project}"
    fi
    pwdp="$wd/genome_view_${project}"
fi

#star index testing
if [ -n "$staridx" -a ! -d "$staridx" ];then
    echo "star index directory does not exist" >&2
    exit 1
fi
#gtf2 for attributes extracting
if [ ! -s "$gtf2" ];then
    echo "file $gtf2 for extracting attributes into the provided $gtf\
    does not exist" >&2
    exit 1
fi
#making a directory for logs files
if [ ! -d "$wd/logs" ];then 
    mkdir "$wd/logs"
fi
logs="$wd/logs"
#running information
echo "Run summary information" > "$wd"/run_summary_information.txt
################################################################################
#splitting tb into one line tables and making a list of tb-splited files
if [ ! -s "$wd/spl_list" ];then 
    split -l 1 "$tb" "$wd/split_" && ls "$wd"| grep "split_" > "$wd/spl_list"
    spl="$wd/spl_list"
fi 
################################################################################

################################################################################
#RAW data generation
################################################################################
#sra download step will be ran if skipv is different from sra
if [ "$val1" != "sra" ];then
    echo "downloading sra files from NCBI"
    #downloading SRA files
    ######################
    #writting a function that takes two arguments, the SRA run name and
    # the sra directory full path download
    #the sra file from the NCBI
    sra_down ()
    {
        x="$1"
        sra="$2"
        wget -O "$sra/${x}.sra" \
        "ftp://ftp-trace.ncbi.nih.gov/sra/sra-instant/reads/ByRun/sra/${x:0:3}/${x:0:6}/${x}/${x}.sra" >& "$logs/wget_${x}.log" || \
        rm "$sra/${x}.sra" #in the case download fails the broken donwloaded file will be removed
    }
    export -f sra_down
    #making a list of sra entries that will be download in parallel
    if [ -s "$sra/sra_down_list" ];then 
        rm "$sra/sra_down_list"
    fi
    while read x discard;do
        #and only SRA files that were not already been downloaded will make up the list
        if [ ! -f "$sra/${x}.sra" ];then
            "$x" >> "$sra/sra_down_list"
        fi
    done < $tb
    #downloading as many sra files in parallel as the number passed with -P or
    #the number of lines of the input_table
    if [ -z "$par2" ];then 
        par2=$(wc -l "$tb" | cut -f1 -d' ')
    fi
    echo "downloading sra files ..."
    cat "$sra/sra_down_list" | nice -n 19 parallel -j "$par2" sra_down {} "$sra"
fi

#dumping the data from SRA to fastq
###################################
#if not skipped - val == dump - dumping will run
if [ "$val" != "dump" ];then
    echo "running fastq-dump"
    echo "running fastq-dump with $(fastq-dump --version)" >> "$wd"/run_summary_information.txt
    #writting down a function that
    #takes the tb input table and use the sra run id to dump the donwloaded files
    #in sra format into fastq files depending on whether they are paired or single
    #end reads base on the second column values of the input table
    dump()
    {
        tb="$1" #the input file for running in parallel
        sra="$2" #sra directory
        pwd1="$3" #fastq directory
        wd="$4" #working directory
        while read x y discard;do
        #if value is set to PAIRED
            if [ "$y" == "PAIRED" ]; then
            #if files does not exist they will not be dumped
                if [ -f "${sra}/$x.sra" ];then
                    n1=$(ls "$pwd1"|grep "$x"|sed "s|^|"$pwd1/"|"| head -n 1)
                    n2=$(ls "$pwd1"|grep "$x"|sed "s|^|"$pwd1/"|"| tail -n 1)
                    #and whether the first or the second fastq file has not been
                    #already dumped
                    if [ ! -f "$n1" -o ! -f "$n2" ];then
                        #the sra file will added to the list of files to dump
                        fastq-dump --split-files --outdir "$pwd1" "${sra}/$x.sra"
                    fi
                elif [ ! -f "${sra}/$x.sra" ];then
                    #if an SRA file does not exist adding to runing summary information
                    echo -e "\tfile ${sra}/$x.sra was not dumped,file does not exist" >> "$wd"/run_summary_information.txt
                fi
            #if value is set to SINGLE
            elif [ "$y" == "SINGLE" ];then
                if [ -f "${sra}/$x.sra" ];then
                    n1=$(ls "$pwd1"|grep "$x"|sed "s|^|"$pwd1/"|")
                    #and the fastq file has not been already dumped
                    if [ ! -f "$n1" ];then
                        #the sra file will be dumped
                        fastq-dump --outdir "$pwd1" "${sra}/$x.sra"
                    fi
                elif [ ! -f "${sra}/$x.sra" ];then
                #if an SRA file does not exist adding to runing summary information
                    echo -e "\tfile ${sra}/$x.sra was not dumped,it does not exist" >> "$wd"/run_summary_information.txt
                fi
                #if a varaible if different from SINGLE or PAIRED, the whole script
                #ends with a non-zero return
            else
                echo -e >&2 "The input table must indicate whether the library layout is\n SINGLE or PAIRED"
                exit 1
            fi
        done < "$tb" #end of the main fastq-dump loop
    }
    export -f dump
    #making a variable for the number of dumping that will run in parallel
    par=$(lscpu|awk 'NR==4{print $2}')
    #dumping in parallel
    echo "dumping sra files..."
    cat "$spl" | nice -n 19 parallel -j $((par/2)) dump {} "$sra" "$pwd1" "$wd"
fi

#ensuring that no fastq files is gziped
for i in $(ls "$pwd1");do
    file "$pwd1/$i" | grep -q "gzip compressed data" \
    && echo "$pwd1/$i" >> "$wd/raw_gzip_files"
done
if [ -s "$wd/raw_gzip_files" ];then
    #number of files to gunzip in parallel
    n=`awk 'END{print NR}' "$wd/raw_gzip_files"` 
    echo "unziping files..."
    cat "$wd/raw_gzip_files" | parallel -j "$n" gunzip {}
    rm "$wd/raw_gzip_files"
    echo "done.."
fi
######################
#QC and trimming stpes
######################
if [ "$val2" != "fastp" ];then
    #creating directories for qc and trimmed files 
    if [ ! -d "$wd/QC_fastq" ];then mkdir "$wd/QC_fastq";fi
    pwd2="$wd/QC_fastq"
    #making a fatqc directeroy in the project_visualization directory
    if [ ! -d "${pwdp}/fastP" ];then mkdir "${pwdp}/fastP";fi
        pwd3="${pwdp}/fastP"
    if [ ! -n "$pwd4" -a ! -d "$wd/trimmed_files" ];then 
        mkdir "$wd/trimmed_files"
        pwd4="$wd/trimmed_files"
    fi
#running fastp for raw files 
    while read x y discard;do
        if [ "$y" == "PAIRED" ];then
            r1=$(ls "$pwd1"|grep "$x"|sed "s|^|"$pwd1/"|"| head -n 1)
            r2=$(ls "$pwd1"|grep "$x"|sed "s|^|"$pwd1/"|"| tail -n 1)
            t1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| head -n 1)
            t2=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| tail -n 1)
            if [ -s "$r1" -a -s "$r2" ] && [ ! -n "$t1" -a ! -n "$t2" ];then
                if [ -n "$adapt" -a ! -s "$pwd2/${x}_fastp.html" ];then 
                    nice -n 19 fastp -i "$r1" -I "$r2" -o "$pwd4/${x}_R1.fq" -O "$pwd4/${x}_R2.fq" \
                    -l 20 -5 3 -3 3 -h "$pwd2/${x}_fastp.html" -j "$pwd2/${x}_fastp.json" -w "$t" \
                    -R "fastp for sample $x" -a $adapt >& "$logs/fastp_${x}.log"
                elif [ ! -s "$pwd2/${x}_fastp.html" ];then
                    nice -n 19 fastp -i "$r1" -I "$r2" -o "$pwd4/${x}_R1.fq" -O "$pwd4/${x}_R2.fq" \
                    -l 20 -5 3 -3 3 -h "$pwd2/${x}_fastp.html" -j "$pwd2/${x}_fastp.json" -w "$t" \
                    -R "fastp for sample $x" >& "$logs/fastp_${x}.log"
                fi 
                if [ -d "$vd" ];then
                    #coping output file into GV directory if it is in a var directory
                    cp "$pwd2/${x}_fastp.html" "$pwd3" || echo "directory $pwd3 if full"
                fi
            fi 
        elif [ "$y" == "SINGLE" ];then
            #assining variables to untrimmed and trimmed fastq files untrimmed fastq files - input for Trimmomatic
            r1=$(ls "$pwd1"|grep "$x"|sed "s|^|"$pwd1/"|")
            #trimmed fastq files - output of Trimmomatic
            t1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|")
            #trimmomatic will run if output file does not exist and input file exist
            if [ -s "$r1" -a ! -n "$t1" ];then
                if [ -n "$adapt" -a ! -s "$pwd2/${x}_fastp.html" ];then 
                    nice -n 19 fastp -i "${r1}" -o "$pwd4/${x}.fq" \
                    -l 20 -5 3 -3 3 -h "$pwd2/${x}.html" -j "$pwd2/${x}.json" -w "$t" \
                    -R "fastp for sample $x" -a $adapt >& "$logs/fastp_${x}.log"
                elif [ ! -s "$pwd2/${x}_fastp.html" ];then 
                    nice -n 19 fastp -i "${r1}" -o "$pwd2/${x}.fq" \
                    -l 20 -5 3 -3 3 -h "$pwd2/${x}.html" -j "$pwd2/${x}.json" -w "$t" \
                    -R "fastp for sample $x" >& "$logs/fastp_${x}.log"
                fi 
                if [ -d "$vd" ];then
                    #coping output file into GV directory if it is in a var directory
                    cp "$pwd2/${x}_fastp.html" "$pwd3" || echo "directory $pwd3 if full"
                fi
            fi
        else
            echo -e "The input table must indicate whether the library layout is\n SINGLE or PAIRED" >&2
            exit 1
        fi
        echo "QC and trim steps by : $(fastp --version | tail -n1)" >> "$wd/run_summary_information.txt"
    done < "$tb"
else 
    pwd4="$pwd1"
    val5="qc_trim"
    echo "downstream analysis will be performed only using untrimmed raw fastq files" >> "$wd/run_summary_information.txt"
    echo "downstream analysis will be performed only using untrimmed raw fastq files"
fi 
    
    
    
###############################################################################
#Reads alignment and QC analysis
###############################################################################
if [ "$val7" != "align" ];then
    echo "reads alignment by  $(star --version)" >> $wd/run_summary_information.txt
    #Alignment by star
    ##################
    #making the star output directory and assigning it a variable
    if [ ! -d "$wd/star_alignment" ];then 
        mkdir "$wd/star_alignment"
    fi
    pwd6="$wd/star_alignment"

  #Genome index generation
  ########################
    #if a genome index is not provided or genome file does not exist
    #star will build an index genome
    if [ "$staridx" == "" -o ! -f "$staridx/Genome" ];then
        echo "building a star index"
        #making a proper star index
        #creating variables for reads alignment step
        if [ ! -d "$pwd6/star_dir" ];then 
            mkdir "$pwd6/star_dir"
        fi
        star_dir="$pwd6/star_dir"
        #max size of reads from the input table minus one
        star_sjodb=$(($(cut -f3 $tb | sort -nr | head -1) - 1))
        #Runing star genomeGenerate running the algorithm for
        #correcting the number of bits per chromosome if the genome is highly segmentated
        if (( $(grep ">" $genome | wc -l) > 5000 ));then
            #genome size
            gsize=$(grep -v ">" $genome|wc|awk '{print $3 -$1}')
            #number of chromosomes
            nchr=$(grep ">" $genome | wc -l)
            sac=$(echo "scale=2;l($gsize/$nchr)/l(2)" | bc -l)
            sac=$(if [ $(echo "$sac < 18" | bc -l) ];then printf "%.0f\n" $sac; else echo 18;fi)
            nice -n 19 star \
                    --runThreadN "$t" --runMode genomeGenerate --genomeDir "$star_dir" \
                    --genomeFastaFiles "$genome" --sjdbGTFfile "$gtf" \
                    --sjdbOverhang "$star_sjodb" --genomeChrBinNbits "$sac" \
                    >& "$logs/star_idx_generation.log"
        #or just building a default star index
        else
            nice -n 19 star \
                    --runThreadN "$t" --runMode genomeGenerate --genomeDir "$star_dir" \
                    --genomeFastaFiles "$genome" --sjdbGTFfile "$gtf" --sjdbOverhang "$star_sjodb" \
                    >& "$logs/star_idx_generation.log"
        fi
    #if star index directory has been provided and exists
    elif [ -n "$staridx" -a -s "$staridx/Genome" ];then
        star_dir="$staridx"
        echo "star index was provided"
        #otherwise end the whole script
    else
        echo -e "the provided star index directory does not exist or Genome file inside directory was not found" >&2
        exit 1
    #end of genome generating step
    fi
#end of loop for skiping star alignment step
#fi
    #Running star 2-pass mappin step with genome re-generation alignment for trimmed files
    ####################################################################################
    #if not skipped the whole trimming process
    #if [ ! -n "$val4" ];then
    #if not skiiping alignment step by star
    #if [ "$val7" != "align" ];then
    echo "running star for pipe_align-trim files..."
    #START OF STAR alignment
    #star first-pass
    echo "starting star first pass"
    while read x y discard;do
        #running mode if they are PAIRED
        if [ "$y" == "PAIRED" ]; then
            #assigning a variable to reads and ziping them if they are unzipped
            #n1=$(ls "$pwd4" |grep "$x" |sed "s|^|"$pwd4/"|"| head -n 1)
            #if [ -f "$n1" ];then
            #file "$n1"| grep -q "gzip" || gzip "$n1";fi
            #n2=$(ls "$pwd4" |grep "$x"|sed "s|^|"$pwd4/"|"| tail -n 1)
            #if [ -f "$n2" ];then
            #file "$n2"| grep -q "gzip" || gzip "$n2";fi
            #reassigning a varaible to reads, to take into acccount changes in zipped extentions -.gz-
            n1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| head -n 1)
            n2=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| tail -n 1)
            #if both fastq files exist star will be run
            if [ -f "$n1" -a -f "$n2" ];then
                #running star only if it has not been already run successfuly
                o=$(ls "$pwd6/${x}"|grep "SJ.out.tab"|sed "s|^|"$pwd6/${x}/"|")
                if [ ! -s "$o" ];then
                    echo "processing fastq file $n1"
                    echo "processing fastq file $n2"
                    #first star running, first pass
                    if [ ! -d "$pwd6/${x}" ];then 
                        mkdir  "$pwd6/${x}"
                    fi
                    echo "running star first pass for $x"
                    nice -n 19 star --runMode alignReads \
                            --genomeDir "$star_dir" --readFilesIn "$n1" "$n2" \
                            --outReadsUnmapped Fastx --chimSegmentMin 12 \
                            --chimJunctionOverhangMin 12 --alignSJDBoverhangMin 10 \
                            --alignMatesGapMax 100000 --alignIntronMax 100000 \
                            --chimSegmentReadGapMax 3 --alignSJstitchMismatchNmax 5 -1 5 5 \
                            --runThreadN "$t" --outSAMstrandField intronMotif \
                            --outFilterMultimapNmax 20 --outFilterType BySJout \
                            --outFilterMismatchNoverReadLmax 0.04 --alignIntronMin 20 \
                            --outSAMtype BAM Unsorted \
                            --outFileNamePrefix "$pwd6/${x}/" >& "$logs/star_first_${x}.log" \
                    || rm -rf "$pwd6/${x}"
                fi
            fi
        elif [ "$y" == "SINGLE" ]; then
            #assigning a variable to reads and unziping them if they are zipped
            #n1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|")
            #if [ -f "$n1" ];then
            #file "$n1"| grep -q "gzip" || gunzip "$n1";fi
            n1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|")
            #running only if fastq file exists
            if [ -f "$n1" ];then
                #running star only if it has not been already run successfuly - SJ.out.tab file exists an has size greather than zero
                o=$(ls "$pwd6/${x}"|grep "SJ.out.tab"|sed "s|^|"$pwd6/${x}/"|")
                if [ ! -s "$o" ];then
                    echo "processing fastq file $n1"
                    #first star running, first pass
                    if [ ! -d "$pwd6/${x}" ];then 
                        mkdir  "$pwd6/${x}"
                    fi
                    echo "running star first pass for $x"
                    nice -n 19 star --runMode alignReads \
                            --genomeDir "$star_dir" --readFilesIn "$n1" \
                            --outReadsUnmapped Fastx --chimSegmentMin 12 \
                            --chimJunctionOverhangMin 12 --alignSJDBoverhangMin 10 \
                            --alignMatesGapMax 100000 --alignIntronMax 100000 \
                            --chimSegmentReadGapMax 3 --alignSJstitchMismatchNmax 5 -1 5 5 \
                            --runThreadN "$t" --outSAMstrandField intronMotif \
                            --outFilterMultimapNmax 20 --outFilterType BySJout \
                            --outFilterMismatchNoverReadLmax 0.04 --alignIntronMin 20 \
                            --outSAMtype BAM Unsorted \
                            --outFileNamePrefix "$pwd6/${x}/" >& "$logs/star_first_${x}.log" \
                    || rm -rf "$pwd6/${x}"
                fi
            fi
        else
            echo -e "The input table must indicate whether the library layout is\nSINGLE or PAIRED" >&2
            exit 1
        fi
    #end of the while loop
    done < $tb
    echo "star first pass done"
    #Genome re-generating with merged SJ.out.tab files from first pass
    ##################################################################
    #not running if regnerate genome already exists
    if [ ! -s "$pwd6/regenerate_star_dir/sjdbList.out.tab" ];then
        #first running the the Rscript for generating SJ.out.tb merged and filter file
        SJ_filter_combine.R trim "$pwd6"
        #creating a file for the new star index genome at star_alignment directory
        echo "starting star genome regeneration"
        if [ ! -d "$pwd6/regenerate_star_dir" ];then 
            mkdir "$pwd6/regenerate_star_dir"
        fi
        re_star_dir="$pwd6/regenerate_star_dir"
        #max size of reads from the input_table minus one
        star_sjodb=$(($(cut -f3 $tb | sort -nr | head -1) - 1))
        #running the algorithm for correcting the number of bits per chromosome
        #if the genome is highly segmentated
        if (( $(grep ">" $genome | wc -l) > 5000 ));then
            #genome size
            gsize=$(grep -v ">" $genome|wc|awk '{print $3 -$1}')
            #number of chromosomes
            nchr=$(grep ">" $genome | wc -l)
            sac=$(echo "scale=2;l($gsize/$nchr)/l(2)" | bc -l)
            sac=$(if [ $(echo "$sac < 18" | bc -l) ];then printf "%.0f\n" $sac;else echo 18;fi)
            nice -n 19 star \
                    --runThreadN "$t" --runMode genomeGenerate \
                    --genomeDir "${re_star_dir}" \
                    --genomeFastaFiles "$genome" --sjdbGTFfile "$gtf" \
                    --sjdbFileChrStartEnd "$pwd6/SJ.out.filter_combine_trim" \
                    --sjdbOverhang "$star_sjodb" \
                    --genomeChrBinNbits "$sac" >& "$logs/star_idx_regeneration.log"
        #or just building a default star index
        else
            nice -n 19 star \
            --runThreadN "$t" --runMode genomeGenerate \
            --genomeDir "${re_star_dir}" \
            --genomeFastaFiles "$genome" --sjdbGTFfile "$gtf" \
            --sjdbFileChrStartEnd "$pwd6/SJ.out.filter_combine_trim" \
            --sjdbOverhang "$star_sjodb" >& "$logs/star_idx_regeneration.log"
        fi
        echo "genome regeneration done"
    else
        re_star_dir="$pwd6/regenerate_star_dir"
        echo "regenerate genome was alredy built"
        #end of already existing regenerated genome conditional
    fi

    #second star running, second pass
    echo "starting star second pass..."
    while read x y discard;do
        #if STAR first pass ends wihout exceptions and star second pass has already been successfully run
        if [ -s "$pwd6/${x}/SJ.out.tab" -a ! -s "$pwd6/${x}/${x}.out.sort.bam.bai" ];then
            #running mode if they are PAIRED
            if [ "$y" == "PAIRED" ]; then
                #assigning a variable to reads
                n1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| head -n 1)
                n2=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| tail -n 1)
                #second star pass
                echo "running star second pass for ${x}"
                nice -n 19 star --runMode alignReads --genomeDir "${re_star_dir}" \
                --readFilesIn "$n1" "$n2" --outReadsUnmapped Fastx \
                --chimSegmentMin 12 --chimJunctionOverhangMin 12 \
                --alignSJDBoverhangMin 10 --alignMatesGapMax 100000 \
                --alignIntronMax 100000 --chimSegmentReadGapMax 3 \
                --alignSJstitchMismatchNmax 5 -1 5 5 --runThreadN "$t" \
                --outSAMstrandField intronMotif --outFilterMultimapNmax 20 \
                --outFilterType BySJout --outFilterMismatchNoverReadLmax 0.04 \
                --alignIntronMin 20 \
                --outSAMtype BAM Unsorted --outMultimapperOrder Random \
                --outFileNamePrefix "$pwd6/${x}/" >& "$logs/star_second_${x}.log" \
                || rm -rf "$pwd6/${x}"
                #sorting bam output file
                echo "sorting output bam file"
                nice -n 19 samtools sort -@ "$t" "$pwd6/${x}/Aligned.out.bam"  >  "$pwd6/${x}/${x}.out.sort.bam"
                #indexing bam output file
                echo "indexing output bam file"
                nice -n 19 samtools index "$pwd6/${x}/${x}.out.sort.bam" "$pwd6/${x}/${x}.out.sort.bam.bai"
                #removing original bam file
                rm "$pwd6/${x}/Aligned.out.bam"
                #modifying Log.final.out file for summarizing all them
                sed -i 's/|//;s/://' "$pwd6/${x}/Log.final.out"
            elif [ "$y" == "SINGLE" ]; then
                #assigning a variable to reads
                n1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|")
                #first star running, first pass
                if [ ! -d "$pwd6/${x}" ];then 
                    mkdir  "$pwd6/${x}"
                fi
                echo "running star second pass for ${x}"
                nice -n 19 star --runMode alignReads \
                    --genomeDir "${re_star_dir}" \
                    --readFilesIn "$n1" --outReadsUnmapped Fastx --chimSegmentMin 12 \
                    --chimJunctionOverhangMin 12 --alignSJDBoverhangMin 10 \
                    --alignMatesGapMax 100000 --alignIntronMax 100000 \
                    --chimSegmentReadGapMax 3 --alignSJstitchMismatchNmax 5 -1 5 5\
                    --runThreadN "$t" --outSAMstrandField intronMotif \
                    --outFilterMultimapNmax 20 \
                    --outFilterType BySJout --outFilterMismatchNoverReadLmax 0.04 \
                    --alignIntronMin 20 --outSAMtype BAM Unsorted \
                    --outMultimapperOrder Random \
                    --outFileNamePrefix "$pwd6/${x}/" >& "$logs/star_second_${x}.log" \
                || rm -rf "$pwd6/${x}"
                #sorting bam output file
                echo "sorting output $x bam file"
                nice -n 19 samtools sort -@ "$t" "$pwd6/${x}/Aligned.out.bam"  >  "$pwd6/${x}/${x}.out.sort.bam"
                #indexing bam output file
                echo "indexing output $x bam file"
                nice -n 19 samtools index "$pwd6/${x}/${x}.out.sort.bam" "$pwd6/${x}/${x}.out.sort.bam.bai"
                #removing original bam file
                rm "$pwd6/${x}/Aligned.out.bam"
                #modifying Log.final.out file for summarizing all them
                sed -i 's/|//;s/://' "$pwd6/${x}/Log.final.out"
            else
                echo -e "The input table must indicate whether the library layout is\nSINGLE or PAIRED" >&2
                exit 1
            fi
        fi
    #end of star second pass  while-loop
    done < $tb
    echo "star second pass done"
    echo "alignment step by of trimmed files during pipe_align:  `star --version`" >> $wd/run_summary_information.txt
    echo "star for pipe_align-trim files ... done!"
    sleep 2
    #end of star alingment skip conditional
    #fi
    if [ "$val6" != "qc_bam" ];then
        echo "bam fastQC analysis by $(fastqc --version)" >> $wd/run_summary_information.txt
        echo "running fastQC for pipe_align-trim bam files ..."
        #Aligned Reads -BAM- fastQC for trimmed files
        ##############################################
        #star-otuput bam Fastqc analysis
        #making a directory for fastqc analysis
        if [ ! -d "${wd}/QC_alignment" ];then
            mkdir "${wd}/QC_alignment"
        fi
        if [ ! -d "${wd}/QC_alignment/fastqc" ];then
            mkdir "${wd}/QC_alignment/fastqc"
        fi
        #assigning a variable to the pathway
        pwd2="${wd}/QC_alignment/fastqc"
        #making a directory for fastqc output
        if [ ! -d "${pwdp}/fastQC_alignment" ];then
            mkdir "${pwdp}/fastQC_alignment"
        fi
        pwd3="${pwdp}/fastQC_alignment"
        #running fastqc for bam files
        while read x discard;do
            if [ ! -d "${pwd2}/${x}" ];then mkdir "${pwd2}/${x}";fi
            #running FASTQC if star ends without exceptions and output file has not been already generated
            if [ -s "${pwd6}/${x}/Log.final.out" -a ! -s "${pwd2}/${x}/${x}.out.sort_fastqc.zip" ];then
                echo "running fastQC for $x bam file"
                nice -n 19 fastqc "$pwd6/${x}/${x}.out.sort.bam" -o "${pwd2}/${x}" -t "$t" --extract
                if [ -d "$vd" ]; then
                    cp "${pwd2}/${x}/${x}.out.sort_fastqc.html" "${pwd3}/${x}_fastqc.html" || echo "directory $pwd3 if full"
                elif [ ! -d "$vd" ]; then
                    mv "${pwd2}/${x}/${x}.out.sort_fastqc.zip" "${pwd3}/${x}_fastqc.zip"
                fi
            fi
        done < $tb
        #end of FASTQC loop for bam file
        echo "fastQC for bam files is done !"
        sleep 2
    fi
#end OF STAR_TRIM -DEFAULT- RUN-LOOP
fi

################################################################################
#transcript building
################################################################################
#Scallop transcriptome assembly per sample
##########################################
#making a directory for aligments outputs:bigwig files, scallop and taco, fasta transcriptome
if [ ! -d "$wd/assembly_star" ];then mkdir "$wd/assembly_star";fi
assembly_star="$wd/assembly_star"
if [ ! -d "$assembly_star/scallop_built" ];then mkdir "$assembly_star/scallop_built";fi
scallop="$assembly_star/scallop_built"
#runnig scallop
if [ ! -n "$val4" ];then
    echo "bam to gtf by sacallop $(scallop --version)" >> $wd/run_summary_information.txt
    while read x discard;do
        if [ ! -s "$scallop/$x.gtf" -a -s "$pwd6/${x}/${x}.out.sort.bam" ];then
            echo "running scallop for $sra"
            lib_type=$(scallop_lib_type.sh "$pwd6/${x}/${x}.out.sort.bam" "$bed")
            nice -n 19 scallop -i "$pwd6/${x}/${x}.out.sort.bam" \
            --library_type "$lib_type" --min_transcript_length_base 200 \
            --min_mapping_quality 30 --min_splice_bundary_hits 3 \
            -o "$scallop/$x.gtf" >& "$logs/scallop_$x.log"
        fi
    done < "$tb"
    echo "scallop step ... done!"
fi

#Merging of scallop gtf files by taco and comparing with reference gtf
######################################################################
#first directory for output files will be created and variables assigned
if [ ! -d "$assembly_star/taco_merge" ];then mkdir "$assembly_star/taco_merge";fi
taco="$assembly_star/taco_merge"
#adding missing attributes to genomebrowser gtf file from well
#annotated gtf -gtf2- file
if [ -s "$gtf2" -a ! -s "$taco/ref_annotated.gtf" ];then
    echo "merging gtf annotation"
    merge_gtf.R "$gtf" "$gtf2" "$taco/ref_annotated"
    gtf="$taco/ref_annotated.gtf"
fi
##################################
#if trimmed steps were not skipped
if [ ! -n "$val4" ];then
    #Merging gtf files per condition
    ################################
    #creating a temporary table to be able to run taco for each condition 
    cat "$tb" > "$wd/tb1"
    tb1="$wd/tb1"
    #counting the number of condition columns
    echo "merging gtf files by taco_run and taco_refcomp" >> $wd/run_summary_information.txt
    c=$(awk '{print NF}' "$tb" | uniq)
    #taco merging of gtf files per condition group
    n=4;while [ "$n" -le "$c" ];do
        condition=$(cut -f"$n" "$tb"| sort | uniq)
        for i in $condition;do
            if [ ! -d "$taco/$i" ];then mkdir "$taco/$i";fi
            tdc="$taco/$i"
            rm -f "$tdc/${i}_scallop_group"
            #adding existing files - if input exists
            while read x y z w discard; do
                if [ "$i" == "$w" -a -s "$scallop/$x.gtf" ];then
                    echo "$scallop/$x.gtf" >> "$tdc/${i}_scallop_group"
                    #removing the forth column to iterate over more than one condtion 
                    sed -i -r 's/\S+//4' "$tb1" 
                fi
            done < "$tb1"
            trun="$tdc/run"
            echo "merging scallop gtf files for condition $i"
            #if outuput does not exists
            if [ ! -s "$trun/assembly.gtf" ];then
                nice -n 19 taco_run "$tdc/${i}_scallop_group" -o "$trun" \
                -p "$t" --gtf-expr-attr RPKM \
                --filter-min-length 200 --isoform-frac 0.05 >& "$logs/taco_run_$i.log"
            fi
            comp="$tdc/compare"
            if [ -n "$species" -a ! -s "$comp/assembly.metadata.tsv" ];then
                echo "comparing merged gtf file of condition $i"
                nice -n 19 taco_refcomp -o "$comp" -p "$t" --cpat \
                --cpat-species "$species" --cpat-genome "$genome" \
                -r "$gtf" -t "$trun/assembly.gtf" >& "$logs/taco_refcomp_$i.log"
            elif [ ! -s "$comp/assembly.metadata.tsv" ];then 
                nice -n 19 taco_refcomp -o "$comp" -p "$t" \
                -r "$gtf" -t "$trun/assembly.gtf" >& "$logs/taco_refcomp_$i.log"
            fi
        done
        n=$(( n + 1 ))
    done
    rm -f "$tb1"
    #reassigning the tb original value 
    tb="$tb_prim"
    #Merging all project-sample gtf files
    #####################################
    if [ ! -d "$taco/$project" ];then mkdir "$taco/$project";fi
    tdc="$taco/$project"
    rm -f "$tdc/tomerge_files"
    while read x discard;do
        if [ -s "$scallop/$x.gtf" ];then
            echo "$scallop/$x.gtf" >> "$tdc/tomerge_files"
        fi
    done < "$tb"
    trun="$tdc/run"
    echo "merging scallop gtf files for project $project"
    if [ ! -s "$trun/assembly.gtf" ];then
        nice -n 19 taco_run "$tdc/tomerge_files" -o "$trun" \
        -p "$t" --gtf-expr-attr RPKM \
        --filter-min-length 200 --isoform-frac 0.05 >& "$logs/taco_run_project.log"
    fi
    echo "writting the transcriptome down for $project"
    nice -n 19 bedtools getfasta -fi "$genome" \
    -fo "$trun/${project}.transcriptoma.fa" -bed "$trun/assembly.bed" \
    -name -split -s
    #generating table transcript to genes
    grep ">" "$trun/${project}.transcriptoma.fa" | sed 's/^.*|//; s/(.*)//' > "$trun/transcripts"
    grep ">" "$trun/${project}.transcriptoma.fa" | sed 's/>//; s/|.*)//' > "$trun/genes"
    paste "$trun/transcripts" "$trun/genes" > "$trun/${project}.transcripts_to_genes.tsv"
    cat "$trun/genes" | sort | unique "$trun/list_genes"
    mv -f unique "$trun/list_genes" "$trun/genes"
    #just leaving the transcript taco name in the fasta file
    sed -i 's/^.*|/>/; s/(.*)//' "$trun/${project}.transcriptoma.fa"
    #copying the output bed file to the visualization directory
    if [ ! -d "${pwdp}/assembly_star" ];then mkdir "${pwdp}/assembly_star";fi
    cp "$trun/assembly.bed" "${pwdp}/assembly_star/${project}_transcriptome.bed" \
    || echo "can not copy bed file,directory full"
    comp="$tdc/compare"
    if [ -n "$species" -a ! -s "$comp/assembly.metadata.tsv" ];then
        echo "comparing merged gtf files for project ${project}"
        nice -n 19 taco_refcomp -o "$comp" -p "$t" --cpat \
        --cpat-species "$species" --cpat-genome "$genome" \
        -r "$gtf" -t "$trun/assembly.gtf" >& "$logs/taco_refcomp_project.log"
    elif [ ! -s "$comp/assembly.metadata.tsv" ];then
        nice -n 19 taco_refcomp -o "$comp" -p "$t" \
        -r "$gtf" -t "$trun/assembly.gtf" >& "$logs/taco_refcomp_project.log"
    fi
fi

################################################################################
#transcript-based gene counts
################################################################################
#making the step main directory
if [ ! -d "$wd/counts" ];then mkdir "$wd/counts";fi
counts="$wd/counts"
#Running kallisto for isoform counting
######################################
echo "pseudocounts by  kallisto 0.44.0" >> $wd/run_summary_information.txt
#making a kallisto directory
if [ ! -d "$counts/kallisto" ];then mkdir "$counts/kallisto";fi
kallisto="$counts/kallisto"
if [ ! -d "$kallisto/star_scalop_taco" ];then mkdir "$kallisto/star_scalop_taco";fi
kallisto="$counts/kallisto/star_scalop_taco"
#building kallisto index
kallisto index -i "$kallisto/${project}.idx" --make-unique "$trun/${project}.transcriptoma.fa"
idx="$kallisto/${project}.idx"
#function for run_info.json transformation to tsv, it takes the file path as
#input and return the format-transformed table
j2t () 
    { 
    cat "$1/run_info.json" | grep "[np]_" | sed -n '1, 7 p' |\
    sed 's/"//g;s/://;s/,//;s/\t//;s/ /\t/' > "$1/run_info.tsv"
    }
export -f j2t
#kallisto quantification for sst_based transcriptome
echo "runnign kallisto quantification for star_scalop_taco_based transcriptome"
if [ ! -n "$val4" -a -s "$idx" ];then
    if [ ! -d "$kallisto/raw" ];then mkdir "$kallisto/raw";fi;raw="$kallisto/raw";
    if [ ! -d "$kallisto/trim" ];then mkdir "$kallisto/trim";fi;trim="$kallisto/trim";
    while read x y discard;do
        if [ "$y" == "PAIRED" ];then
            r1=$(ls "$pwd1"|grep "$x"|sed "s|^|"$pwd1/"|"| head -n 1)
            r2=$(ls "$pwd1"|grep "$x"|sed "s|^|"$pwd1/"|"| tail -n 1)
            t1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| head -n 1)
            t2=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| tail -n 1)
            if [ -s "$t1" -a -s "$t2" ];then
                if [ ! -d "$trim/$x" ];then mkdir "$trim/$x";fi;otrim="$trim/$x";
                if [ ! -s "$otrim/run_info.tsv" ];then
                    echo "running kallisto for $x"
                    rule=$(inf_exp.sh "$wd/star_alignment/${x}/${x}.out.sort.bam" "$bed")
                    if [ -n "$rule" ];then
                        kallisto quant -i "$idx" -o "$otrim" --bias -b 100 --rf-stranded \
                        -t "$t" "$t1" "$t2" >& "$logs/kallisto_sst_$x.log"
                    else
                        kallisto quant -i "$idx" -o "$otrim" --bias -b 100 \
                        -t "$t" "$t1" "$t2" >& "$logs/kallisto_sst_$x.log"
                    fi
                    j2t "$otrim"
                fi
            fi
            if [ -s "$r1" -a -s "$r2" ] && [ "$val2" != "fastp" ];then
                if [ ! -d "$raw/$x" ];then mkdir "$raw/$x";fi;oraw="$raw/$x";
                if [ ! -s "$oraw/run_info.tsv" ];then
                    echo "running kallisto for ${x}_raw"
                    rule=$(inf_exp.sh "$wd/star_alignment/${x}/${x}.out.sort.bam" "$bed")
                    if [ -n "$rule" ];then
                        kallisto quant -i "$idx" -o "$oraw" --bias -b 100 --rf-stranded \
                        -t "$t" "$r1" "$r2" >& "$logs/kallisto_sst_${x}_raw.log"
                    else
                        kallisto quant -i "$idx" -o "$oraw" --bias -b 100 \
                        -t "$t" "$r1" "$r2" >& "$logs/kallisto_sst_${x}_raw.log"
                    fi
                    j2t "$oraw"
                fi
            fi
        elif [ "$y" == "SINGLE" ];then
            r1=$(ls "$pwd1"|grep "$x"|sed "s|^|"$pwd1/"|")
            t1=$(ls "$pwd1"|grep "$x"|sed "s|^|"$pwd1/"|")
            if [ -s "$t1" ];then
                if [ ! -d "$trim/$x" ];then mkdir "$trim/$x";fi;otrim="$trim/$x";
                if [ ! -s "$otrim/run_info.tsv" ];then
                    echo "running kallisto for sample $x"
                    rule=$(inf_exp.sh "$wd/star_alignment/${x}/${x}.out.sort.bam" "$bed")
                    if [ -n "$rule" ];then
                        kallisto quant -i "$idx" -o "$otrim" --single -l 200 -s 20 --bias \
                        -b 100 --rf-stranded -t "$t" "$t1" >& "$logs/kallisto_sst_$x.log"
                    else
                        kallisto quant -i "$idx" -o "$otrim" --single -l 200 -s 20 --bias \
                        -b 100 -t "$t" "$t1" >& "$logs/kallisto_sst_$x.log"
                    fi
                    j2t "$otrim"
                fi
            fi
            if [ -s "$r1" -a "$val2" != "fastp" ];then
                if [ ! -d "$raw/$x" ];then mkdir "$raw/$x";fi;oraw="$raw/$x";
                if [ ! -s "$oraw/run_info.tsv" ];then
                    echo "running kallisto for sample ${x}_raw"
                    rule=$(inf_exp.sh "$wd/star_alignment/${x}/${x}.out.sort.bam" "$bed")
                    if [ -n "$rule" ];then
                        kallisto quant -i "$idx" -o "$oraw" --single -l 200 -s 20 --bias \
                        -b 100 --rf-stranded -t "$t" "$r1" >& "$logs/kallisto_sst_${x}_raw.log"
                    else
                        kallisto quant -i "$idx" -o "$oraw" --single -l 200 -s 20 --bias \
                        -b 100 -t "$t" "$r1"  >& "$logs/kallisto_sst_${x}_raw.log"
                    fi
                    j2t "$oraw"
                fi
            fi
        fi
    done < "$tb"
fi

#running kallisto for genecode_based transcriptome
if [ ! -d "$counts/kallisto" ];then mkdir "$counts/kallisto";fi
kallisto="$counts/kallisto"
if [ ! -d "$kallisto/genecode" ];then mkdir "$kallisto/genecode";fi
kallisto="$counts/kallisto/genecode"
idx="$idx_gb" #passed kallisto index from the last genome browser gencode
#running kallisto quantification if ensembl kallisto is provided
echo "running kallisto for genecode_based transcriptome"
if [ ! -n "$val4" -a -s "$idx" ];then
    if [ ! -d "$kallisto/raw" ];then mkdir "$kallisto/raw";fi;raw="$kallisto/raw";
    if [ ! -d "$kallisto/trim" ];then mkdir "$kallisto/trim";fi;trim="$kallisto/trim";
    while read x y discard;do
        if [ "$y" == "PAIRED" ];then
            r1=$(ls "$pwd1"|grep "$x"|sed "s|^|"$pwd1/"|"| head -n 1)
            r2=$(ls "$pwd1"|grep "$x"|sed "s|^|"$pwd1/"|"| tail -n 1)
            t1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| head -n 1)
            t2=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| tail -n 1)
            if [ -s "$t1" -a -s "$t2" ];then
                if [ ! -d "$trim/$x" ];then mkdir "$trim/$x";fi;otrim="$trim/$x";
                if [ ! -s "$otrim/run_info.tsv" ];then
                    echo "running kallisto for ${x}"
                    rule=$(inf_exp.sh "$wd/star_alignment/${x}/${x}.out.sort.bam" "$bed")
                    if [ -n "$rule" ];then
                        kallisto quant -i "$idx" -o "$otrim" --bias -b 100 --rf-stranded \
                        -t "$t" "$t1" "$t2" >& "$logs/kallisto_genecode_$x.log"
                    else
                        kallisto quant -i "$idx" -o "$otrim" --bias -b 100 \
                        -t "$t" "$t1" "$t2" >& "$logs/kallisto_genecode_$x.log"
                    fi
                    j2t "$otrim"
                fi
            fi
            if [ -s "$r1" -a -s "$r2" ] && [ "$val2" != "fastp" ];then
                if [ ! -d "$raw/$x" ];then mkdir "$raw/$x";fi;oraw="$raw/$x";
                if [ ! -s "$oraw/run_info.tsv" ];then
                    echo "running kallisto for ${x}_raw"
                    rule=$(inf_exp.sh "$wd/star_alignment/${x}/${x}.out.sort.bam" "$bed")
                    if [ -n "$rule" ];then
                        kallisto quant -i "$idx" -o "$oraw" --bias -b 100 --rf-stranded \
                        -t "$t" "$r1" "$r2" >& "$logs/kallisto_genecode_${x}_raw.log"
                    else
                        kallisto quant -i "$idx" -o "$oraw" --bias -b 100 \
                        -t "$t" "$r1" "$r2" >& "$logs/kallisto_genecode_${x}_raw.log"
                    fi
                    j2t "$oraw"
                fi
            fi
        elif [ "$y" == "SINGLE" ];then
            r1=$(ls "$pwd1"|grep "$x"|sed "s|^|"$pwd1/"|")
            t1=$(ls "$pwd1"|grep "$x"|sed "s|^|"$pwd1/"|")
            if [ -s "$t1" ];then
                if [ ! -d "$trim/$x" ];then mkdir "$trim/$x";fi;otrim="$trim/$x";
                if [ ! -s "$otrim/run_info.tsv" ];then
                    echo "running kallisto for ${x}"
                    rule=$(inf_exp.sh "$wd/star_alignment/${x}/${x}.out.sort.bam" "$bed")
                    if [ -n "$rule" ];then
                        kallisto quant -i "$idx" -o "$otrim" --single -l 200 -s 20 --bias \
                        -b 100 --rf-stranded -t "$t" "$t1" >& "$logs/kallisto_genecode_${x}.log"
                    else
                        kallisto quant -i "$idx" -o "$otrim" --single -l 200 -s 20 --bias \
                        -b 100 -t "$t" "$t1" >& "$logs/kallisto_genecode_${x}.log"
                    fi
                    j2t "$otrim"
                fi
            fi
            if [ -s "$r1" -a "$val2" != "fastp" ];then
                if [ ! -d "$raw/$x" ];then mkdir "$raw/$x";fi;oraw="$raw/$x";
                if [ ! -s "$oraw/run_info.tsv" ];then
                    echo "running kallisto for ${x}_raw"
                    rule=$(inf_exp.sh "$wd/star_alignment/${x}/${x}.out.sort.bam" "$bed")
                    if [ -n "$rule" ];then
                        kallisto quant -i "$idx" -o "$oraw" --single -l 200 -s 20 --bias \
                        -b 100 --rf-stranded -t "$t" "$r1" >& "$logs/kallisto_genecode_${x}_raw.log"
                    else
                        kallisto quant -i "$idx" -o "$oraw" --single -l 200 -s 20 --bias \
                        -b 100 -t "$t" "$r1" >& "$logs/kallisto_genecode_${x}_raw.log"
                    fi
                    j2t "$oraw"
                fi
            fi
        fi
    done < "$tb"
fi

#runnning RSEM for gene and isoform counting
############################################
#RSEM for sst_based transcriptome 
if [ ! -d "$counts/rsem" ];then mkdir "$counts/rsem";fi;rsem="$counts/rsem";
gtf="$wd/assembly_star/taco_merge/$project/compare/assembly.refcomp.gtf"
if [ ! -d "$rsem/star_index" ];then mkdir "$rsem/star_index";fi;rsem_idx="$rsem/star_index/${project}_";
#buidling an rsem reference based on the mereged gtf file (taco_refcompare output)
if [ ! -s "$rsem/star_index/sjdbList.out.tab" ];then
    rsem-prepare-reference --gtf "$gtf" --star -p "$t" "$genome" "$rsem_idx"
fi
echo "pseudocounts by  rsem" >> $wd/run_summary_information.txt
  #running RSEM for each sample
  if [ ! -n "$val4" ];then
    while read x y discard;do
        if [ ! -d "$rsem/$x" ];then mkdir "$rsem/$x";fi;out="$rsem/$x/rsem";
        rule=$(inf_exp.sh "$wd/star_alignment/${x}/${x}.out.sort.bam" "$bed")
        if [ -n "$rule" ];then
            if [ "$y" == "PAIRED" ];then
                n1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| head -n 1)
                n2=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| tail -n 1)
                if [ -s "$n1" -a -s "$n2" ];then
                  if [ ! -s "${out}.isoforms.results" ];then
                    echo "running rsem for sample $x"
                    rsem-calculate-expression --star -p "$t" \
                                            --paired-end --forward-prob 0 \
                                            --estimate-rspd --no-bam-output --append-names \
                                            "$n1" "$n2" "$rsem_idx" "$out" >& "$logs/rsem_sst_${x}.log"
                    rsem-plot-model "$out" "${out}_plot_model.pdf"
                  fi
                fi
            elif [ "$y" == "SINGLE" ];then
                n1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|")
                if [ -s "$n1" ];then
                  if [ ! -s "${out}.isoforms.results" ];then
                    echo "running rsem for sample $x"
                    rsem-calculate-expression --star -p "$t" \
                                            --forward-prob 0 \
                                            --estimate-rspd --no-bam-output --append-names \
                                            "$n1" "$n2" "$rsem_idx" "$out" >& "$logs/rsem_sst_${x}.log"
                    rsem-plot-model "$out" "${out}_plot_model.pdf"
                  fi
                fi
            fi
        else
            if [ "$y" == "PAIRED" ];then
                n1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| head -n 1)
                n2=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| tail -n 1)
                if [ -s "$n1" -s "$n2" ];then
                  if [ ! -s "${out}.isoforms.results" ];then
                    echo "running rsem for sample $x"
                    rsem-calculate-expression --star -p "$t" \
                                            --paired-end \
                                            --estimate-rspd --no-bam-output --append-names \
                                            "$n1" "$n2" "$rsem_idx" "$out" >& "$logs/rsem_sst_${x}.log"
                    rsem-plot-model "$out" "${out}_plot_model.pdf"
                  fi
                fi
            elif [ "$y" == "SINGLE" ];then
                n1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|")
                if [ -s "$n1" ];then
                  if [ ! -s "${out}.isoforms.results" ];then
                    echo "running rsem for sample $x"
                    rsem-calculate-expression --star -p "$t" \
                                            --estimate-rspd --no-bam-output --append-names \
                                            "$n1" "$n2" "$rsem_idx" "$out">& "$logs/rsem_sst_${x}.log"
                    rsem-plot-model "$out" "${out}_plot_model.pdf"
                  fi
                fi
            fi
        fi
    done < "$tb"
  fi
#RSEM for genome browser-based transcriptome 
if [ ! -d "$counts/rsem" ];then mkdir "$counts/rsem";fi;rsem="$counts/rsem";
gtf="$taco/ref_annotated.gtf"
#gb stands for genome browser 
if [ ! -d "$rsem/star_index_gb" ];then mkdir "$rsem/star_index_gb";fi;rsem_idx="$rsem/star_index_gb/${project}_";
#buidling an rsem reference based on the mereged gtf file (taco_refcompare output)
if [ ! -s "$rsem/star_index/sjdbList.out.tab" ];then
    rsem-prepare-reference --gtf "$gtf" --star -p "$t" "$genome" "$rsem_idx"
fi
echo "counts by  rsem" >> $wd/run_summary_information.txt
  #running RSEM for each sample
  if [ ! -n "$val4" ];then
    while read x y discard;do
        if [ ! -d "$rsem/${x}_gb" ];then mkdir "$rsem/${x}_gb";fi;out="$rsem/${x}_gb/rsem";
        rule=$(inf_exp.sh "$wd/star_alignment/${x}/${x}.out.sort.bam" "$bed")
        if [ -n "$rule" ];then
            if [ "$y" == "PAIRED" ];then
                n1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| head -n 1)
                n2=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| tail -n 1)
                if [ -s "$n1" -a -s "$n2" ];then
                  if [ ! -s "${out}.isoforms.results" ];then
                    echo "running rsem for sample $x"
                    rsem-calculate-expression --star -p "$t" \
                                            --paired-end --forward-prob 0 \
                                            --estimate-rspd --no-bam-output --append-names \
                                            "$n1" "$n2" "$rsem_idx" "$out" >& "$logs/rsem_gb_${x}.log"
                    rsem-plot-model "$out" "${out}_plot_model.pdf"
                  fi
                fi
            elif [ "$y" == "SINGLE" ];then
                n1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|")
                if [ -s "$n1" ];then
                  if [ ! -s "${out}.isoforms.results" ];then
                    echo "running rsem for sample $x"
                    rsem-calculate-expression --star -p "$t" \
                                            --forward-prob 0 \
                                            --estimate-rspd --no-bam-output --append-names \
                                            "$n1" "$n2" "$rsem_idx" "$out" >& "$logs/rsem_gb_${x}.log"
                    rsem-plot-model "$out" "${out}_plot_model.pdf"
                  fi
                fi
            fi
        else
            if [ "$y" == "PAIRED" ];then
                n1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| head -n 1)
                n2=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| tail -n 1)
                if [ -s "$n1" -s "$n2" ];then
                  if [ ! -s "${out}.isoforms.results" ];then
                    echo "running rsem for sample $x"
                    rsem-calculate-expression --star -p "$t" \
                                            --paired-end \
                                            --estimate-rspd --no-bam-output --append-names \
                                            "$n1" "$n2" "$rsem_idx" "$out" >& "$logs/rsem_gb_${x}.log"
                    rsem-plot-model "$out" "${out}_plot_model.pdf"
                  fi
                fi
            elif [ "$y" == "SINGLE" ];then
                n1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|")
                if [ -s "$n1" ];then
                  if [ ! -s "${out}.isoforms.results" ];then
                    echo "running rsem for sample $x"
                    rsem-calculate-expression --star -p "$t" \
                                            --estimate-rspd --no-bam-output --append-names \
                                            "$n1" "$n2" "$rsem_idx" "$out">& "$logs/rsem_gb_${x}.log"
                    rsem-plot-model "$out" "${out}_plot_model.pdf"
                  fi
                fi
            fi
        fi
    done < "$tb"
  fi
##############################################################################################################
#differentail expressed analysis at gene, transcript and exon level based on the newly assembled transcriptome
##############################################################################################################

################################################################################
#coverage
################################################################################
#making a directory for aligments outputs:bigwig files, scallop and taco, fasta transcriptome
if [ ! -d "$wd/assembly_star" ];then mkdir "$wd/assembly_star";fi
assembly_star="$wd/assembly_star"
if [ ! -d "${pwdp}/assembly_star" ];then mkdir "${pwdp}/assembly_star";fi
pas="${pwdp}/assembly_star"
#bigwig step
############
#if the whole bigwig step was not skipped
if [ "$val8" != "bw" ];then
    if [ ! -d "${assembly_star}/bw" ];then mkdir "${assembly_star}/bw";fi
    #step global variables
    bw="${assembly_star}/bw"
    chrsize="${re_star_dir}/chrNameLength.txt"
    #runnning if not trim steps were skipped
    if [ ! -n "$val4" ];then
        #generating bigwig files with RseQC
        echo "generating bigwig file/s for pipe_aling trimmed files"
        #writting down a function that will allow run in parallel the
        #transformation from bam to bigwig
        bw_trim()
        {
            tb="$1"
            pwd6="$2"
            bed="$3"
            bw="$4"
            chrsize="$5"
            pas="$6"
            while read x y discard;do
                #if sorted indexed bam file exists - if input exist- then
                if [ -s "$pwd6/${x}/${x}.out.sort.bam.bai" ];then
                    #assining a variable to strandness rule
                    rule=$(inf_exp.sh "$pwd6/${x}/${x}.out.sort.bam" "$bed")
                    wigsum=$(bam2bw.norm.R "$pwd6/${x}/")
                    echo "sample ${x} has as rule ${rule} and a total wigsum of ${wigsum}"\
                    > "$pwd6/${x}/running_arguments.txt"
                if [ -n "$rule" ]; then
                    #if library was strand specific and output does not exist then
                    if [ ! -s "$bw/${x}.Forward.bw" -a ! -s "$bw/${x}_raw.Reverse.bw" ];then
                        echo "runnig bam2wig for $x"
                        nice -n 19 bam2wig.py -i "$pwd6/${x}/${x}.out.sort.bam" \
                        -s "$chrsize" -o "$bw/${x}" -t "$wigsum" \
                        -d "$rule" >& "$logs/bigwig_generation_${x}.log"
                        rm -f $(ls "$bw"|grep "${x}"|sed "s|^|$bw/|"|grep "wig")
                        cp $(ls "$bw"|grep "${x}"|sed "s|^|$bw/|"|grep "bw") "$pas" \
                        || echo "can not be able to copy file, please check directory space"
                    fi
                else
                    #if library was not strand specific and output does not exist then
                    if [ ! -s "$bw/${x}.bw" ];then
                        echo "running bam2wig for $x"
                        nice -n 19 bam2wig.py -i "$pwd6/${x}/${x}.out.sort.bam" \
                        -s "$chrsize" -o "$bw/${x}" \
                        -t "$wigsum" >& "$logs/bigwig_generation_${x}.log"
                        rm -f $(ls "$bw"|grep "${x}"|sed "s|^|$bw/|"|grep "wig")
                        cp $(ls "$bw"|grep "${x}"|sed "s|^|$bw/|"|grep "bw") "$pas" \
                        || echo "can not be able to copy file, please check directory space"
                    fi
                fi
            fi
            done < "$tb"
        }
        export -f bw_trim
        #running in parallel
        cat "$spl" | parallel -j "$t" bw_trim {} "$pwd6" "$bed" "$bw" "$chrsize" "$pas"
        echo "bigwig files generation was done ..!"
        sleep 2
    fi
#end of bigwig generation step
fi
#Splicing saturation analysis
##############################
#if splicing QC step was not skipped then run it
if [ "$val9" != "sqc" ];then
    #running for bam pipe_align trimmed files if not skipped
    if [ ! -d "${wd}/QC_alignment" ];then mkdir "${wd}/QC_alignment";fi
    qc_align="${wd}/QC_alignment"
    if [ ! -d "$qc_align/splicing" ];then mkdir "$qc_align/splicing";fi
    qc_splice="$qc_align/splicing"
    #QC for splicing analysis it will look for only unique mapped reads as phred is set to 30,default
    #and the minimun intron length is set to 20 -m as it was the already set as an star argument in pipe_align
    junction_trim()
    {
        tb="$1"
        qc_splice="$2"
        pwd6="$3"
        bed="$4"
        while read s discard;do
            #if final output does not exist and input exists then
            if [ ! -s "$qc_splice/${s}/jSat_table" -a -s "$pwd6/${s}/${s}.out.sort.bam" ];then
                if [ ! -d "$qc_splice/${s}/" ];then mkdir "$qc_splice/${s}/";fi
                nice -n 19 junction_annotation.py -i "$pwd6/${s}/${s}.out.sort.bam" \
                -r "$bed" -o "$qc_splice/${s}/s" -m 20 >& "$logs/splicing_qc_annotation_${x}.log"
                nice -n 19 junction_saturation.py -i "$pwd6/${s}/${s}.out.sort.bam" \
                -r "$bed" -o "$qc_splice/${s}/s" -m 20 >& "$logs/splicing_qc_saturation_${x}.log"
                for i in {x,y,z,w};do
                    grep "$i=" "$qc_splice/${s}/s.junctionSaturation_plot.r" |\
                    cut -f2 -d'=' | sed "s|^c(||" | sed "s|)$||" |\
                    sed "s|^|$i,|" >> "$qc_splice/${s}/jSat_table"
                done
            fi
        done < "$tb"
    }
  export -f junction_trim
  #running in parallel
  cat "$spl" | parallel -j "$t" junction_trim {} "$qc_splice" "$pwd6" "$bed"
  echo "splicing QC analysis for bam files ... done !"
  sleep 2
#end of the main loop for splicing QC analysis skipping
fi
#project coverage analysis
###########################
#as it is a time consumming step it will only run for pipe_align-trim files
#or for pipe_align-raw files if trim steps were skipped
#running geneBody_coverage if it was not skipped
if [ "$val10" != "cov" ];then
    if [ ! -n "$val4" ];then
        if [ ! -d "${wd}/QC_alignment" ];then mkdir "${wd}/QC_alignment";fi
        qc_align="${wd}/QC_alignment"
        if [ ! -d "$qc_align/coverage" ];then mkdir "$qc_align/coverage";fi
        cover="$qc_align/coverage"
        rm -f "${cover}/bam_files.txt"
        while read x discard;do
            #adding bam files only if they are being generated
            if [ -s "$pwd6/${x}/${x}.out.sort.bam" ];then
                echo  "$pwd6/${x}/${x}.out.sort.bam" >> "${cover}/bam_files.txt"
            fi
        done < "$tb"
    fi
    #running geneBody_coverage in transcript samples with a length greater than 200 (-l)
    if [ -s "$trun/${project}.transcritome.bed" ];then
        bed_file="$trun/${project}.transcritome.bed"
    else
        bed_file="$bed"
    fi
    ##running in paralle
    #function to call geneBody_coverage.py in parallel
    coverage_imp()
    {
    bam_file="$1"
    bed_file="$2"
    cover="$3"
    project="$4"
    while read x y discard;do
        nice -n 19 geneBody_coverage.py -i "$x" -r "$bed_file" -l 200 -o "${cover}/${project}_$y"
    done < "$bam_file"
    }
    export -f coverage_imp
    #files split
    a=`awk 'END{print NR}' "$cover/bam_files.txt"` #number of bam files to process
    b=$(( a % t )) #rest of division, number of files to run with number of threads
    c=$(( a / t )) #division of number of lines with number of threads to split the bam files running in parallel
    #if there is less bam files to run than threads to run in parallel then split the files into single ones, running in parallel all the files
    if [ "$c" -eq 0 ];then
        split -l 1 "$cover/bam_files.txt" "$cover/bam_split_"
        n=1;for i in $(ls "$cover" | grep "bam_split_");do
            echo "$n" > "$cover/f${n}"
            paste "$cover/$i" "$cover/f${n}" > "$cover/bam_file_${n}"
            n=$(( n + 1))
        done
        rm -f $(ls "$cover"|grep "f[1-9]"|sed "s|^|"$cover/"|")
        ls "$cover" | grep "bam_file_" > "$cover/bam_files"
        sed -i "s|^|"$cover/"|" "$cover/bam_files"
        echo "running geneBody_coverage.py in parallel"
        cat "$cover/bam_files" | parallel -j "$t" coverage_imp {} "$bed_file" "$cover" "$project"
        #if there are  more files than $threads avaialble for running in parallel then
    elif [ "$c" -gt 0 ];then
        tail -n +$((b + 1)) "$cover/bam_file.txt" > "$cover/bam_files_to_split"
        head -n "$b" "$cover/bam_file.txt" > "$cover/bam_file_rest"
        split -l "$c" "$cover/bam_files_to_split" "$cover/bam_split_b"
        #appending rest files to as many split_files as number of rest files
        n=1;for i in $(ls "$cover" |grep "bam_split_b"| sed "s|^|"$cover/"|");do
          rest["$n"]="$i"
          n=$(( n + 1 ))
        done
        n=1;for i in $(cat "$cover/bam_file_rest");do
          echo "$i" >> ${rest["$n"]}
          n=$(( n + 1 ))
        done
    #generating file to run geneBody_coverage in parallel
        n=1;for i in $(ls "$cover" | grep "bam_split_b");do
          echo "$n" > "$cover/f${n}"
          paste "$cover/$i" "$cover/f${n}" > "$cover/bam_file_b${n}"
          n=$(( n + 1))
        done
        rm -f $(ls "$cover"|grep "f[0-9]"|sed "s|^|"$cover/"|")
        ls "$cover" | grep "bam_file_b" > "$cover/bam_files_b"
        sed -i "s|^|"$cover/"|" "$cover/bam_files_b"
        #running geneBody_coverage in parallel
        echo "running geneBody_coverage.py in parallel"
        cat "$cover/bam_files_b" | parallel -j "$t" coverage_imp {} "$bed_file" "$cover" "$project"
    fi
      #files ran in parallel
    for i in $(ls "$cover"| grep geneBodyCoverage.txt); do
        echo "$cover/$i" >> "$cover/geneCov_meta_table"
    done
    #number of bam files run in each batch
    for i in $(cat "$cover/geneCov_meta_table");do
        awk 'END{print NR - 1}' "$i" >> "$cover/NR_geneCov"
    done
    paste "$cover/geneCov_meta_table" "$cover/NR_geneCov" > "$cover/geneCov_meta_table_out"
    #spliting the out tables into group of 12
    n=0;z=1;while read x y discard;do
        n=$(( n + y ))
        if [ "$n" -le "12" ];then
            echo "$x" >> "$cover/out_group_${z}"
        else
            n="$y"
            z=$(( z + 1))
            echo "$x" >> "$cover/out_group_${z}"
        fi
    done < "$cover/geneCov_meta_table_out"
    ls "$cover" | grep "out_group_"| sed "s|^|"$cover/"|" > "$cover/parallel_geneCov_groups"
    n=$(awk 'END{print NR}' "$cover/parallel_geneCov_groups")
    for i in $(seq 1 "$n");do
        echo "$cover/geneCov_out_${i}" >> "$cover/out_group_names"
    done
    paste "$cover/parallel_geneCov_groups" "$cover/out_group_names" > "$cover/parallel_geneCov_groups_out"
    split -l 1 "$cover/parallel_geneCov_groups_out" "$cover/geneCov_split_"
    ls "$cover" | grep "geneCov_split_" | sed "s|^|"$cover/"|" > "$cover/parallel_geneCov_groups_out"
    #running geneBody coverge plotting Rscript in parallel
    geneBody_coverage_plot()
    {
        tb="$1"
        while read x y discard;do
            parallel_geneCove_wrawppe.R "$x" "$y"
        done < "$tb"
    }
    export -f geneBody_coverage_plot
    cat "$cover/parallel_geneCov_groups_out" | parallel -j "$t" geneBody_coverage_plot {}
    rm -f $(ls "$cover" | grep -v "pdf" | sed "s|^|"$cover/"|")
#end of the main loop
fi
#if is not skipped fastQC for trimmed files will run at the end of the pipeline 
if [ "$val5" != "qc_trim" ];then
    echo "running FASTQC of trimmed files"
    sleep 2
    #Making diectories for trimmed-fastq-files fastqc output data
    if [ ! -d $wd/QC_fastq/trim ];then mkdir $wd/QC_fastq/trim;fi
    pwd2=$wd/QC_fastq/trim
    if [ ! -d ${pwdp}/fastQC_trim ];then mkdir ${pwdp}/fastQC_trim;fi
    pwd3=${pwdp}/fastQC_trim
    #and reasigning the pwd4 value to directory in case it was lost 
    if [ ! -n "$pwd4" -a ! -d "$wd/trimmed_files" ];then 
        mkdir "$wd/trimmed_files"
        pwd4="$wd/trimmed_files"
    fi
    #running fastqc for fastq_trimmed files 
    while read x y discard;do
        #if fastq are paired-end
        if [ "$y" == "PAIRED" ];then
            #if input files exists fastqc will run
            t1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| head -n 1)
            o1="${pwd2}/${x}_1_fastqc.html"
            t2=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|"| tail -n 1)
            o2="${pwd2}/${x}_2_fastqc.html"
            if [ -f "$t1" -a -f "$t2" ];then
                echo "running fastQC for $x fastq trimmed file"
                if [ ! -s "$o1" ];then 
                    nice -n 19 fastqc "$t1" -o $pwd2 -t "$t" --extract
                fi 
                if [ ! -s "$o2" ];then 
                    nice -n 19 fastqc "$t2" -o $pwd2 -t "$t" --extract
                fi 
                if [ -d "$vd" ];then
                    #coping output file into GV directory if it is in a var directory
                    cp "${pwd2}/${x}_1_fastqc.html" $pwd3 || echo "directory $pwd3 if full"
                    cp "${pwd2}/${x}_2_fastqc.html" $pwd3 || echo "directory $pwd3 if full"
                elif [ ! -d "$vd" ];then
                    #or moving to GV if it is in the working directory
                    mv "${pwd2}/${x}_1_fastqc.zip" $pwd3
                    mv "${pwd2}/${x}_2_fastqc.zip" $pwd3
                fi
            fi
        elif [ "$y" == "SINGLE" ]; then
            t1=$(ls "$pwd4"|grep "$x"|sed "s|^|"$pwd4/"|")
            o1="${pwd2}/${x}_fastqc.html"
            if [ -f "$t1" ];then
                echo "running fastQC for $x fastq trimmed file"
                if [ ! -s "$o1" ];then 
                    nice -n 19 fastqc "$t1" -o $pwd2 -t "$t" --extract
                fi
                if [ -d $vd ]; then
                    cp "${pwd2}/${x}_fastqc.html" $pwd3 || echo "directory $pwd3 if full"
                elif [ ! -d $vd ]; then
                    mv "${pwd2}/${x}_fastqc.zip" $pwd3
                fi
            fi
        else
            echo -e "The input table must indicate whether the library layout is\n SINGLE or PAIRED" >&2
            exit 1
        fi
    done < $tb
    echo "trimmed fastQC by :  `fastqc --version`" >> $wd/run_summary_information.txt
#end of the FATQC-_Trim loop
fi
###################################
#ziping files
###################################
echo "ziping raw files..."
while read x discard;do
    ls "$pwd1" | grep "$x" >> "$pwd1/gzip_files"
done < "$tb"
sed -i "s|^|"$pwd1/"|" "$pwd1/gzip_files"
n=$(awk 'END{print NR}'"$pwd1/gzip_files")
cat "$pwd1/gzip_files" | parallel -j "$n" {}
echo "ziping trim files..."
while read x discard;do
    ls "$pwd4" | grep "$x" >> "$pwd4/gzip_files"
done < "$tb"
sed -i "s|^|"$pwd4/"|" "$pwd4/gzip_files"
n=$(awk 'END{print NR}'"$pwd4/gzip_files")
cat "$pwd4/gzip_files" | parallel -j "$n" {}
#removing split_handle files
echo "removing handle files"
rm -f $(ls "$wd"|grep "split_"| sed "s|^|"$wd/"|")
rm "$wd/spl_list"
echo "pipe_align has done its job !!"
echo ":)"

exit 0
